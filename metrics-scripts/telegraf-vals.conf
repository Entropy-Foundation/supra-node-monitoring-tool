[agent]
    hostname = "{{ agent_name }}"
  flush_interval = "30s"
  interval = "30s"
  collection_jitter = "5s"
  debug = true  

# Read metrics about cpu usage
[[inputs.cpu]]
  ## Whether to report per-cpu stats or not
  percpu = false
  ## Whether to report total system cpu stats or not
  totalcpu = true
  ## If true, collect raw CPU time metrics
  collect_cpu_time = false
  ## If true, compute and report the sum of all non-idle CPU states
  report_active = false

[[inputs.mem]]

[[inputs.system]]

[[inputs.disk]]
  mount_points = ["/"]
[[inputs.diskio]]
[[inputs.processes]]
# Sysstat metrics collector
# Sysstat metrics collector
# This plugin ONLY supports Linux
[[inputs.sysstat]]
  ## Path to the sadc command.
  #
  ## Common Defaults:
  ##   Debian/Ubuntu: /usr/lib/sysstat/sadc
  ##   Arch:          /usr/lib/sa/sadc
  ##   RHEL/CentOS:   /usr/lib64/sa/sadc
  sadc_path = "/usr/lib/sysstat/sadc" # required

  ## Path to the sadf command, if it is not in PATH
  # sadf_path = "/usr/bin/sadf"

  ## Activities is a list of activities, that are passed as argument to the
  ## sadc collector utility (e.g: DISK, SNMP etc...)
  ## The more activities that are added, the more data is collected.
   activities = ["DISK"]

  ## Group metrics to measurements.
  ##
  ## If group is false each metric will be prefixed with a description
  ## and represents itself a measurement.
  ##
  ## If Group is true, corresponding metrics are grouped to a single measurement.
  # group = true

  ## Options for the sadf command. The values on the left represent the sadf options and
  ## the values on the right their description (which are used for grouping and prefixing metrics).
  ##
  ## Run 'sar -h' or 'man sar' to find out the supported options for your sysstat version.
  [inputs.sysstat.options]
    -C = "cpu"
    -B = "paging"
    -b = "io"
    -d = "disk"             # requires DISK activity
    "-n ALL" = "network"
    "-P ALL" = "per_cpu"
    -q = "queue"
#    -R = "mem"
    -r = "mem_util"
    -S = "swap_util"
    -u = "cpu_util"
    -v = "inode"
    -W = "swap"
    -w = "task"
  # -H = "hugepages"        # only available for newer linux distributions
  # "-I ALL" = "interrupts" # requires INT activity

  ## Device tags can be used to add additional tags for devices. For example the configuration below
  ## adds a tag vg with value rootvg for all metrics with sda devices.
  # [[inputs.sysstat.device_tags.sda]]
  #  vg = "rootvg"
[[inputs.procstat]]
  pattern = ".*"
[[inputs.nstat]]
[[inputs.net]]

[[inputs.exec]]
  commands = ["/bin/bash -c 'curl -s https://gist.githubusercontent.com/Supra-RaghulRajeshR/33d027b21be6f190c0c66e34fee3a9a1/raw/131f56b49ea294d320b159a379775f7d63b50acb/check_port.sh | bash -s 28000'"]
  timeout = "5s"
  data_format = "influx"

[[inputs.exec]]
  commands = ["/bin/bash -c 'curl -s https://gist.githubusercontent.com/Supra-RaghulRajeshR/33d027b21be6f190c0c66e34fee3a9a1/raw/e2f74c3ba010a64ef1aa98fe3d521f922b53130a/docker_version.sh | bash -s validator-node'"]
  timeout = "5s"
  data_format = "value"
  data_type = "string"
  name_override = "supra_version"

[[inputs.exec]]
  command = "/bin/bash -c 'curl -s https://gist.githubusercontent.com/Supra-RaghulRajeshR/33d027b21be6f190c0c66e34fee3a9a1/raw/671ecc535adb594d771029d44b6f2d58cd9c9106/total_transaction_2.sh | bash -s {{ LOG_PATH }}'"
  timeout = "600s"
  data_format = "influx"
 # data_type = "string"
  name_override = "total_transactions" 
  interval = "300s"


[[inputs.exec]]
  command = "/bin/bash -c 'curl -s https://gist.githubusercontent.com/Supra-RaghulRajeshR/33d027b21be6f190c0c66e34fee3a9a1/raw/af6ad516dc3dfb8c2d3952956fee705a03895c36/epoch-vals.py | python3 - {{ LOG_PATH }}'"
  timeout = "600s"
  data_format = "influx"
  name_override = "epoch_metrics" 
  interval = "300s"

[[inputs.exec]]
  command = "/bin/bash -c 'curl -s https://gist.githubusercontent.com/Supra-RaghulRajeshR/33d027b21be6f190c0c66e34fee3a9a1/raw/671ecc535adb594d771029d44b6f2d58cd9c9106/vals_participate.sh | bash -s {{ LOG_PATH }}'"
  timeout = "600s"
  data_format = "value"
  data_type ="string"
  name_override = "count_vals"
  interval = "300s"


[[inputs.exec]]
  command = "/bin/bash -c 'curl -s https://gist.githubusercontent.com/Supra-RaghulRajeshR/33d027b21be6f190c0c66e34fee3a9a1/raw/671ecc535adb594d771029d44b6f2d58cd9c9106/block_rate.py | python3 - {{ LOG_PATH }}'"
  timeout = "15s"
  data_format = "influx"
  name_override = "block_rate"
 

[[inputs.exec]]
  command = "/bin/bash -c 'curl -s https://gist.githubusercontent.com/Supra-RaghulRajeshR/33d027b21be6f190c0c66e34fee3a9a1/raw/671ecc535adb594d771029d44b6f2d58cd9c9106/vals_count.sh | bash -s {{ LOG_PATH }}'"
  timeout = "600s"
  data_format = "value"
  data_type = "integer"
  name_override = "vals_participated" 
  interval = "300s"
  
[[inputs.exec]]
  command = "/bin/bash -c 'curl -s https://gist.githubusercontent.com/Supra-RaghulRajeshR/33d027b21be6f190c0c66e34fee3a9a1/raw/671ecc535adb594d771029d44b6f2d58cd9c9106/sync.py | python3 - {{ LOG_PATH }}'"
  data_format = "influx"
  name_override = "sync_status"
  interval = "300s"

[[inputs.file]]
  files = ["/tmp/geo.json"]
  data_format = "json"                
  json_string_fields = [] 
  name_override = "node_geolocation"      

[[inputs.exec]]
  command = "/bin/bash -c 'curl -s https://gist.githubusercontent.com/Supra-RaghulRajeshR/33d027b21be6f190c0c66e34fee3a9a1/raw/fe43393e38fd494556357b6fef2e04107e5fad86/blocks.py | python3 - {{ LOG_PATH }}'"
  timeout = "15s"
  data_format = "influx"
  name_override = "block_values"

[[inputs.exec]]
  command = "/bin/bash -c 'curl -s https://gist.githubusercontent.com/Supra-RaghulRajeshR/33d027b21be6f190c0c66e34fee3a9a1/raw/671ecc535adb594d771029d44b6f2d58cd9c9106/txn-metrics.py | python3 - {{ LOG_PATH }}'"
  timeout = "15s"
  data_format = "influx"
  name_override = "metrics_txn"
  
[[inputs.exec]]
  command = "/bin/bash -c 'curl -s https://gist.githubusercontent.com/Supra-RaghulRajeshR/33d027b21be6f190c0c66e34fee3a9a1/raw/671ecc535adb594d771029d44b6f2d58cd9c9106/master_dash_val.py | python3 - {{ LOG_PATH }}'"
  data_format = "influx"
  name_override = "validator_metrics"
  # interval = "300s"

[[inputs.exec]]
  command = "/bin/bash -c 'curl -s https://gist.githubusercontent.com/Supra-RaghulRajeshR/33d027b21be6f190c0c66e34fee3a9a1/raw/671ecc535adb594d771029d44b6f2d58cd9c9106/consensus_latency.py | python3 - {{ LOG_PATH }}'"
  timeout = "30s"
  data_format = "influx"
  name_override = "consensus_latency"
  
[[inputs.exec]]
  command = "/bin/bash -c 'curl -s https://gist.githubusercontent.com/Supra-RaghulRajeshR/33d027b21be6f190c0c66e34fee3a9a1/raw/671ecc535adb594d771029d44b6f2d58cd9c9106/mainnet_validator.py | python3 - {{ LOG_PATH }}'"
  data_format = "influx"
  name_override = "mainnet_validator"
  # interval = "300s"
  timeout = "60s"


[[outputs.influxdb_v2]]
  ## The URLs of the InfluxDB cluster nodes.
  ##
  ## Multiple URLs can be specified for a single cluster, only ONE of the
  ## urls will be written to each interval.
  ##   ex: urls = ["https://us-west-2-1.aws.cloud2.influxdata.com"]
  urls = ["http://34.100.248.227:8086"]

  ## Token for authentication.
  token = "P7jDj8aK40pnSqfyX4m4OZy878PK1wd6B_ZPhRjeIeY6mqA-XVRZinqjFh2GdE6sS5O_jK92Cj5P9IZ0v-qBNw=="
  timeout = "15s"
  ## Organization is the name of the organization you wish to write to; must exist.
  organization = "Entropy Foundation"

  ## Destination bucket to write into.
  bucket = "supra-metrics"
